:py:mod:`anomalib.utils.sweep`
==============================

.. py:module:: anomalib.utils.sweep

.. autoapi-nested-parse::

   Utils for Benchmarking and Sweep.



Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   helpers/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   config/index.rst


Package Contents
----------------


Functions
~~~~~~~~~

.. autoapisummary::

   anomalib.utils.sweep.flatten_sweep_params
   anomalib.utils.sweep.get_run_config
   anomalib.utils.sweep.set_in_nested_config
   anomalib.utils.sweep.get_meta_data
   anomalib.utils.sweep.get_openvino_throughput
   anomalib.utils.sweep.get_sweep_callbacks
   anomalib.utils.sweep.get_torch_throughput



.. py:function:: flatten_sweep_params(params_dict: omegaconf.DictConfig) -> omegaconf.DictConfig

   Flatten the nested parameters section of the config object.

   We need to flatten the params so that all the nested keys are concatenated into a single string.
   This is useful when
   - We need to do a cartesian product of all the combinations of the configuration for grid search.
   - Save keys as headers for csv
   - Add the config to `wandb` sweep.

   :param params_dict: DictConfig: The dictionary containing the hpo parameters in the original, nested, structure.

   :returns: flattened version of the parameter dictionary.


.. py:function:: get_run_config(params_dict: omegaconf.DictConfig) -> Generator[omegaconf.DictConfig, None, None]

   Yields configuration for a single run.

   :param params_dict: Configuration for grid search.
   :type params_dict: DictConfig

   .. rubric:: Example

   >>> dummy_config = DictConfig({
       "parent1":{
           "child1": ['a', 'b', 'c'],
           "child2": [1, 2, 3]
       },
       "parent2":['model1', 'model2']
   })
   >>> for run_config in get_run_config(dummy_config):
   >>>    print(run_config)
   {'parent1.child1': 'a', 'parent1.child2': 1, 'parent2': 'model1'}
   {'parent1.child1': 'a', 'parent1.child2': 1, 'parent2': 'model2'}
   {'parent1.child1': 'a', 'parent1.child2': 2, 'parent2': 'model1'}
   ...

   :Yields: *Generator[DictConfig]* -- Dictionary containing flattened keys
            and values for current run.


.. py:function:: set_in_nested_config(config: omegaconf.DictConfig, keymap: List, value: Any)

   Set an item in a nested config object using a list of keys.

   :param config: DictConfig: nested DictConfig object
   :param keymap: List[str]: list of keys corresponding to item that should be set.
   :param value: Any: Value that should be assigned to the dictionary item at the specified location.

   .. rubric:: Example

   >>> dummy_config = DictConfig({
       "parent1":{
           "child1": ['a', 'b', 'c'],
           "child2": [1, 2, 3]
       },
       "parent2":['model1', 'model2']
   })
   >>> model_config = DictConfig({
       "parent1":{
           "child1": 'e',
           "child2": 4,
       },
       "parent3": False
   })
   >>> for run_config in get_run_config(dummy_config):
   >>>    print("Original model config", model_config)
   >>>    print("Suggested config", run_config)
   >>>    for param in run_config.keys():
   >>>        set_in_nested_config(model_config, param.split('.'), run_config[param])
   >>>    print("Replaced model config", model_config)
   >>>    break
   Original model config {'parent1': {'child1': 'e', 'child2': 4}, 'parent3': False}
   Suggested config {'parent1.child1': 'a', 'parent1.child2': 1, 'parent2': 'model1'}
   Replaced model config {'parent1': {'child1': 'a', 'child2': 1}, 'parent3': False, 'parent2': 'model1'}


.. py:function:: get_meta_data(model: anomalib.models.components.AnomalyModule, input_size: Tuple[int, int]) -> Dict

   Get meta data for inference.

   :param model: Trained model from which the metadata is extracted.
   :type model: AnomalyModule
   :param input_size: Input size used to resize the pixel level mean and std.
   :type input_size: Tuple[int, int]

   :returns: Metadata as dictionary.
   :rtype: (Dict)


.. py:function:: get_openvino_throughput(config: Union[omegaconf.DictConfig, omegaconf.ListConfig], model_path: pathlib.Path, test_dataset: torch.utils.data.DataLoader, meta_data: Dict) -> float

   Runs the generated OpenVINO model on a dummy dataset to get throughput.

   :param config: Model config.
   :type config: Union[DictConfig, ListConfig]
   :param model_path: Path to folder containing the OpenVINO models. It then searches `model.xml` in the folder.
   :type model_path: Path
   :param test_dataset: The test dataset used as a reference for the mock dataset.
   :type test_dataset: DataLoader
   :param meta_data: Metadata used for normalization.
   :type meta_data: Dict

   :returns: Inference throughput
   :rtype: float


.. py:function:: get_sweep_callbacks() -> List[pytorch_lightning.Callback]

   Gets callbacks relevant to sweep.

   :param config: Model config loaded from anomalib
   :type config: Union[DictConfig, ListConfig]

   :returns: List of callbacks
   :rtype: List[Callback]


.. py:function:: get_torch_throughput(config: Union[omegaconf.DictConfig, omegaconf.ListConfig], model: anomalib.models.components.AnomalyModule, test_dataset: torch.utils.data.DataLoader, meta_data: Dict) -> float

   Tests the model on dummy data. Images are passed sequentially to make the comparision with OpenVINO model fair.

   :param config: Model config.
   :type config: Union[DictConfig, ListConfig]
   :param model: Model on which inference is called.
   :type model: Path
   :param test_dataset: The test dataset used as a reference for the mock dataset.
   :type test_dataset: DataLoader
   :param meta_data: Metadata used for normalization.
   :type meta_data: Dict

   :returns: Inference throughput
   :rtype: float


