:py:mod:`anomalib.deploy.inferencers.torch`
===========================================

.. py:module:: anomalib.deploy.inferencers.torch

.. autoapi-nested-parse::

   This module contains Torch inference implementations.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.deploy.inferencers.torch.TorchInferencer




.. py:class:: TorchInferencer(config: Union[omegaconf.DictConfig, omegaconf.ListConfig], model_source: Union[str, pathlib.Path, anomalib.models.components.AnomalyModule], meta_data_path: Union[str, pathlib.Path] = None)

   Bases: :py:obj:`anomalib.deploy.inferencers.base.Inferencer`

   PyTorch implementation for the inference.

   :param config: Configurable parameters that are used
                  during the training stage.
   :type config: DictConfig
   :param model_source: Path to the model ckpt file or the Anomaly model.
   :type model_source: Union[str, Path, AnomalyModule]
   :param meta_data_path: Path to metadata file. If none, it tries to load the params
                          from the model state_dict. Defaults to None.
   :type meta_data_path: Union[str, Path], optional

   .. py:method:: _load_meta_data(self, path: Optional[Union[str, pathlib.Path]] = None) -> Union[Dict, omegaconf.DictConfig]

      Load metadata from file or from model state dict.

      :param path: Path to metadata file. If none, it tries to load the params
                   from the model state_dict. Defaults to None.
      :type path: Optional[Union[str, Path]], optional

      :returns: Dictionary containing the meta_data.
      :rtype: Dict


   .. py:method:: load_model(self, path: Union[str, pathlib.Path]) -> anomalib.models.components.AnomalyModule

      Load the PyTorch model.

      :param path: Path to model ckpt file.
      :type path: Union[str, Path]

      :returns: PyTorch Lightning model.
      :rtype: (AnomalyModule)


   .. py:method:: pre_process(self, image: numpy.ndarray) -> torch.Tensor

      Pre process the input image by applying transformations.

      :param image: Input image
      :type image: np.ndarray

      :returns: pre-processed image.
      :rtype: Tensor


   .. py:method:: forward(self, image: torch.Tensor) -> torch.Tensor

      Forward-Pass input tensor to the model.

      :param image: Input tensor.
      :type image: Tensor

      :returns: Output predictions.
      :rtype: Tensor


   .. py:method:: post_process(self, predictions: torch.Tensor, meta_data: Optional[Union[Dict, omegaconf.DictConfig]] = None) -> Tuple[numpy.ndarray, float]

      Post process the output predictions.

      :param predictions: Raw output predicted by the model.
      :type predictions: Tensor
      :param meta_data: Meta data. Post-processing step sometimes requires
                        additional meta data such as image shape. This variable comprises such info.
                        Defaults to None.
      :type meta_data: Dict, optional

      :returns: Post processed predictions that are ready to be visualized.
      :rtype: np.ndarray



