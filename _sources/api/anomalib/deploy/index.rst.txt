:py:mod:`anomalib.deploy`
=========================

.. py:module:: anomalib.deploy

.. autoapi-nested-parse::

   Functions for Inference and model deployment.



Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   inferencers/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   optimize/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.deploy.OpenVINOInferencer
   anomalib.deploy.TorchInferencer



Functions
~~~~~~~~~

.. autoapisummary::

   anomalib.deploy.export_convert
   anomalib.deploy.get_model_metadata



.. py:class:: OpenVINOInferencer(config: Union[omegaconf.DictConfig, omegaconf.ListConfig], path: Union[str, pathlib.Path, Tuple[bytes, bytes]], meta_data_path: Union[str, pathlib.Path] = None)

   Bases: :py:obj:`anomalib.deploy.inferencers.base.Inferencer`

   OpenVINO implementation for the inference.

   :param config: Configurable parameters that are used
                  during the training stage.
   :type config: DictConfig
   :param path: Path to the openvino onnx, xml or bin file.
   :type path: Union[str, Path]
   :param meta_data_path: Path to metadata file. Defaults to None.
   :type meta_data_path: Union[str, Path], optional

   .. py:method:: load_model(self, path: Union[str, pathlib.Path, Tuple[bytes, bytes]])

      Load the OpenVINO model.

      :param path: Path to the onnx or xml and bin files
                   or tuple of .xml and .bin data as bytes.
      :type path: Union[str, Path, Tuple[bytes, bytes]]

      :returns:

                Input and Output blob names
                    together with the Executable network.
      :rtype: [Tuple[str, str, ExecutableNetwork]]


   .. py:method:: pre_process(self, image: numpy.ndarray) -> numpy.ndarray

      Pre process the input image by applying transformations.

      :param image: Input image.
      :type image: np.ndarray

      :returns: pre-processed image.
      :rtype: np.ndarray


   .. py:method:: forward(self, image: numpy.ndarray) -> numpy.ndarray

      Forward-Pass input tensor to the model.

      :param image: Input tensor.
      :type image: np.ndarray

      :returns: Output predictions.
      :rtype: np.ndarray


   .. py:method:: post_process(self, predictions: numpy.ndarray, meta_data: Optional[Union[Dict, omegaconf.DictConfig]] = None) -> Tuple[numpy.ndarray, float]

      Post process the output predictions.

      :param predictions: Raw output predicted by the model.
      :type predictions: np.ndarray
      :param meta_data: Meta data. Post-processing step sometimes requires
                        additional meta data such as image shape. This variable comprises such info.
                        Defaults to None.
      :type meta_data: Dict, optional

      :returns: Post processed predictions that are ready to be visualized.
      :rtype: np.ndarray



.. py:class:: TorchInferencer(config: Union[omegaconf.DictConfig, omegaconf.ListConfig], model_source: Union[str, pathlib.Path, anomalib.models.components.AnomalyModule], meta_data_path: Union[str, pathlib.Path] = None)

   Bases: :py:obj:`anomalib.deploy.inferencers.base.Inferencer`

   PyTorch implementation for the inference.

   :param config: Configurable parameters that are used
                  during the training stage.
   :type config: DictConfig
   :param model_source: Path to the model ckpt file or the Anomaly model.
   :type model_source: Union[str, Path, AnomalyModule]
   :param meta_data_path: Path to metadata file. If none, it tries to load the params
                          from the model state_dict. Defaults to None.
   :type meta_data_path: Union[str, Path], optional

   .. py:method:: _load_meta_data(self, path: Optional[Union[str, pathlib.Path]] = None) -> Union[Dict, omegaconf.DictConfig]

      Load metadata from file or from model state dict.

      :param path: Path to metadata file. If none, it tries to load the params
                   from the model state_dict. Defaults to None.
      :type path: Optional[Union[str, Path]], optional

      :returns: Dictionary containing the meta_data.
      :rtype: Dict


   .. py:method:: load_model(self, path: Union[str, pathlib.Path]) -> anomalib.models.components.AnomalyModule

      Load the PyTorch model.

      :param path: Path to model ckpt file.
      :type path: Union[str, Path]

      :returns: PyTorch Lightning model.
      :rtype: (AnomalyModule)


   .. py:method:: pre_process(self, image: numpy.ndarray) -> torch.Tensor

      Pre process the input image by applying transformations.

      :param image: Input image
      :type image: np.ndarray

      :returns: pre-processed image.
      :rtype: Tensor


   .. py:method:: forward(self, image: torch.Tensor) -> torch.Tensor

      Forward-Pass input tensor to the model.

      :param image: Input tensor.
      :type image: Tensor

      :returns: Output predictions.
      :rtype: Tensor


   .. py:method:: post_process(self, predictions: torch.Tensor, meta_data: Optional[Union[Dict, omegaconf.DictConfig]] = None) -> Tuple[numpy.ndarray, float]

      Post process the output predictions.

      :param predictions: Raw output predicted by the model.
      :type predictions: Tensor
      :param meta_data: Meta data. Post-processing step sometimes requires
                        additional meta data such as image shape. This variable comprises such info.
                        Defaults to None.
      :type meta_data: Dict, optional

      :returns: Post processed predictions that are ready to be visualized.
      :rtype: np.ndarray



.. py:function:: export_convert(model: anomalib.models.components.AnomalyModule, input_size: Union[List[int], Tuple[int, int]], onnx_path: Union[str, pathlib.Path], export_path: Union[str, pathlib.Path])

   Export the model to onnx format and convert to OpenVINO IR.

   :param model: Model to convert.
   :type model: AnomalyModule
   :param input_size: Image size used as the input for onnx converter.
   :type input_size: Union[List[int], Tuple[int, int]]
   :param onnx_path: Path to output onnx model.
   :type onnx_path: Union[str, Path]
   :param export_path: Path to exported OpenVINO IR.
   :type export_path: Union[str, Path]


.. py:function:: get_model_metadata(model: anomalib.models.components.AnomalyModule) -> Dict[str, torch.Tensor]

   Get meta data related to normalization from model.

   :param model: Anomaly model which contains metadata related to normalization.
   :type model: AnomalyModule

   :returns: metadata
   :rtype: Dict[str, Tensor]


