:py:mod:`anomalib.pre_processing`
=================================

.. py:module:: anomalib.pre_processing

.. autoapi-nested-parse::

   Utilities for pre-processing the input before passing to the model.



Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   transforms/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   pre_process/index.rst
   tiler/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.pre_processing.PreProcessor
   anomalib.pre_processing.Tiler




.. py:class:: PreProcessor(config: Optional[Union[str, albumentations.Compose]] = None, image_size: Optional[Union[int, Tuple]] = None, to_tensor: bool = True)

   Applies pre-processing and data augmentations to the input and returns the transformed output.

   Output could be either numpy ndarray or torch tensor.
   When `PreProcessor` class is used for training, the output would be `torch.Tensor`.
   For the inference it returns a numpy array.

   :param config: Transformation configurations.
                  When it is ``None``, ``PreProcessor`` only applies resizing. When it is ``str``
                  it loads the config via ``albumentations`` deserialisation methos . Defaults to None.
   :type config: Optional[Union[str, A.Compose]], optional
   :param image_size: When there is no config,
   :type image_size: Optional[Union[int, Tuple[int, int]]], optional
   :param ``image_size`` resizes the image. Defaults to None.:
   :param to_tensor: Boolean to check whether the augmented image is transformed
                     into a tensor or not. Defaults to True.
   :type to_tensor: bool, optional

   .. rubric:: Examples

   >>> import skimage
   >>> image = skimage.data.astronaut()

   >>> pre_processor = PreProcessor(image_size=256, to_tensor=False)
   >>> output = pre_processor(image=image)
   >>> output["image"].shape
   (256, 256, 3)

   >>> pre_processor = PreProcessor(image_size=256, to_tensor=True)
   >>> output = pre_processor(image=image)
   >>> output["image"].shape
   torch.Size([3, 256, 256])


   Transforms could be read from albumentations Compose object.
       >>> import albumentations as A
       >>> from albumentations.pytorch import ToTensorV2
       >>> config = A.Compose([A.Resize(512, 512), ToTensorV2()])
       >>> pre_processor = PreProcessor(config=config, to_tensor=False)
       >>> output = pre_processor(image=image)
       >>> output["image"].shape
       (512, 512, 3)
       >>> type(output["image"])
       numpy.ndarray

   Transforms could be deserialized from a yaml file.
       >>> transforms = A.Compose([A.Resize(1024, 1024), ToTensorV2()])
       >>> A.save(transforms, "/tmp/transforms.yaml", data_format="yaml")
       >>> pre_processor = PreProcessor(config="/tmp/transforms.yaml")
       >>> output = pre_processor(image=image)
       >>> output["image"].shape
       torch.Size([3, 1024, 1024])

   .. py:method:: get_transforms(self) -> albumentations.Compose

      Get transforms from config or image size.

      :returns:

                List of albumentation transformations to apply to the
                    input image.
      :rtype: A.Compose


   .. py:method:: __call__(self, *args, **kwargs)

      Return transformed arguments.



.. py:class:: Tiler(tile_size: Union[int, Sequence], stride: Union[int, Sequence], remove_border_count: int = 0, mode: str = 'padding', tile_count: int = 4)

   Tile Image into (non)overlapping Patches. Images are tiled in order to efficiently process large images.

   :param tile_size: Tile dimension for each patch
   :param stride: Stride length between patches
   :param remove_border_count: Number of border pixels to be removed from tile before untiling
   :param mode: Upscaling mode for image resize.Supported formats: padding, interpolation

   .. rubric:: Examples

   >>> import torch
   >>> from torchvision import transforms
   >>> from skimage.data import camera
   >>> tiler = Tiler(tile_size=256,stride=128)
   >>> image = transforms.ToTensor()(camera())
   >>> tiles = tiler.tile(image)
   >>> image.shape, tiles.shape
   (torch.Size([3, 512, 512]), torch.Size([9, 3, 256, 256]))

   >>> # Perform your operations on the tiles.

   >>> # Untile the patches to reconstruct the image
   >>> reconstructed_image = tiler.untile(tiles)
   >>> reconstructed_image.shape
   torch.Size([1, 3, 512, 512])

   .. py:method:: __validate_size_type(parameter: Union[int, Sequence]) -> Tuple[int, Ellipsis]
      :staticmethod:


   .. py:method:: __random_tile(self, image: torch.Tensor) -> torch.Tensor

      Randomly crop tiles from the given image.

      :param image: input image to be cropped

      Returns: Randomly cropped tiles from the image


   .. py:method:: __unfold(self, tensor: torch.Tensor) -> torch.Tensor

      Unfolds tensor into tiles.

      This is the core function to perform tiling operation.

      :param tensor: Input tensor from which tiles are generated.

      Returns: Generated tiles


   .. py:method:: __fold(self, tiles: torch.Tensor) -> torch.Tensor

      Fold the tiles back into the original tensor.

      This is the core method to reconstruct the original image from its tiled version.

      :param tiles: Tiles from the input image, generated via __unfold method.

      :returns: Output that is the reconstructed version of the input tensor.


   .. py:method:: tile(self, image: torch.Tensor, use_random_tiling: Optional[bool] = False) -> torch.Tensor

      Tiles an input image to either overlapping, non-overlapping or random patches.

      :param image: Input image to tile.

      .. rubric:: Examples

      >>> from anomalib.data.tiler import Tiler
      >>> tiler = Tiler(tile_size=512,stride=256)
      >>> image = torch.rand(size=(2, 3, 1024, 1024))
      >>> image.shape
      torch.Size([2, 3, 1024, 1024])
      >>> tiles = tiler.tile(image)
      >>> tiles.shape
      torch.Size([18, 3, 512, 512])

      :returns: Tiles generated from the image.


   .. py:method:: untile(self, tiles: torch.Tensor) -> torch.Tensor

      Untiles patches to reconstruct the original input image.

      If patches, are overlapping patches, the function averages the overlapping pixels,
      and return the reconstructed image.

      :param tiles: Tiles from the input image, generated via tile()..

      .. rubric:: Examples

      >>> from anomalib.datasets.tiler import Tiler
      >>> tiler = Tiler(tile_size=512,stride=256)
      >>> image = torch.rand(size=(2, 3, 1024, 1024))
      >>> image.shape
      torch.Size([2, 3, 1024, 1024])
      >>> tiles = tiler.tile(image)
      >>> tiles.shape
      torch.Size([18, 3, 512, 512])
      >>> reconstructed_image = tiler.untile(tiles)
      >>> reconstructed_image.shape
      torch.Size([2, 3, 1024, 1024])
      >>> torch.equal(image, reconstructed_image)
      True

      :returns: Output that is the reconstructed version of the input tensor.



