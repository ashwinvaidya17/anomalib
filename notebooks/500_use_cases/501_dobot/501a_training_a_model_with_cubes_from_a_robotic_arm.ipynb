{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of production line with defects\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will train a Anomalib model using the Anomalib API and our own dataset. This notebook is also part of the Dobot series notebooks.\n",
    "\n",
    "### Use case\n",
    "\n",
    "Using the [Dobot Magician](https://www.dobot.cc/dobot-magician/product-overview.html) we could simulate a production line system. Imagine we have a cubes factory and they need to know when a defect piece appear in the process. We know very well what is the aspecto of the normal cubes. Defects are coming no often and we need to put those defect cubes out of the production line.\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/10940214/174126337-b344bbdc-6343-4d85-93e8-0cb1bf39a4e3.png\" alt=\"drawing\" style=\"width:400px;\"/>\n",
    "\n",
    "| Class    | Yellow cube                                                                                                                                           | Red cube                                                                                                                                              | Green cube                                                                                                                                            | Inferencing using Anomalib                                                                                                                            |\n",
    "| -------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| Normal   | <img src=\"https://user-images.githubusercontent.com/10940214/174083561-38eec918-efc2-4ceb-99b1-bbb4c91396b2.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | <img src=\"https://user-images.githubusercontent.com/10940214/174083638-85ff889c-6222-4428-9c7d-9ad62bd15afe.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | <img src=\"https://user-images.githubusercontent.com/10940214/174083707-364177d4-373b-4891-96ce-3e5ea923e440.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | <img src=\"https://user-images.githubusercontent.com/10940214/174129305-03d9b71c-dfd9-492f-b42e-01c5c24171cc.jpg\" alt=\"drawing\" style=\"width:150px;\"/> |\n",
    "| Abnormal | <img src=\"https://user-images.githubusercontent.com/10940214/174083805-df0a0b03-58c7-4ba8-af50-fd94d3a13e58.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | <img src=\"https://user-images.githubusercontent.com/10940214/174083873-22699523-22b4-4a55-a3da-6520095af8af.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | <img src=\"https://user-images.githubusercontent.com/10940214/174083944-38d5a6f4-f647-455b-ba4e-69482dfa3562.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | <img src=\"https://user-images.githubusercontent.com/10940214/174129253-f7a567d0-84f7-4050-8065-f00ba8bb973d.jpg\" alt=\"drawing\" style=\"width:150px;\"/> |\n",
    "\n",
    "Using Anomalib we are expecting to see this result.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Anomalib\n",
    "\n",
    "The easiest way to install anomalib is to use pip. You can install it from the command line using the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:05.570263248Z",
     "start_time": "2024-01-12T14:54:05.558579461Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install anomalib[full]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:11.025493595Z",
     "start_time": "2024-01-12T14:54:05.574377979Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"501a_training_a_model_with_cubes_from_a_robotic_arm.ipynb.\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from anomalib.data.utils import read_image\n",
    "from anomalib.deploy import OpenVINOInferencer\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset and Robot API/Driver\n",
    "\n",
    "We should prepare the folder to save the dataset and the Dobot API and drivers. To download the dataset and the Dobot API and drivers we will use anomalib's `download_and_extract` utility function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:15.891806347Z",
     "start_time": "2024-01-12T14:54:11.066629064Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cubes.zip: 6.99MB [00:02, 2.58MB/s]                            \n",
      "dobot_api.zip: 3.69MB [00:02, 1.80MB/s]                            \n"
     ]
    }
   ],
   "source": [
    "from anomalib.data.utils import DownloadInfo, download_and_extract\n",
    "\n",
    "dataset_download_info = DownloadInfo(\n",
    "    name=\"cubes.zip\",\n",
    "    url=\"https://github.com/openvinotoolkit/anomalib/releases/download/dobot/cubes.zip\",\n",
    "    hash=\"e6e067f9e0979a4d190dd2cb1db227d7\",\n",
    ")\n",
    "api_download_info = DownloadInfo(\n",
    "    name=\"dobot_api.zip\",\n",
    "    url=\"https://github.com/openvinotoolkit/anomalib/releases/download/dobot/dobot_api.zip\",\n",
    "    hash=\"89d6d6400cdff03de3c25d2c54f2b443\",\n",
    ")\n",
    "download_and_extract(root=Path.cwd(), info=dataset_download_info)\n",
    "download_and_extract(root=Path.cwd(), info=api_download_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: Cubes\n",
    "\n",
    "Prepare your own dataset for normal and defect pieces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:16.144540948Z",
     "start_time": "2024-01-12T14:54:15.893608154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image_path', 'label', 'image'])\n"
     ]
    }
   ],
   "source": [
    "from anomalib.data.folder import Folder\n",
    "from anomalib.data.task_type import TaskType\n",
    "\n",
    "datamodule = Folder(\n",
    "    root=Path.cwd() / \"cubes\",\n",
    "    normal_dir=\"normal\",\n",
    "    abnormal_dir=\"abnormal\",\n",
    "    normal_split_ratio=0.2,\n",
    "    image_size=(256, 256),\n",
    "    train_batch_size=32,\n",
    "    eval_batch_size=32,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    ")\n",
    "datamodule.setup()  # Split the data to train/val/test/prediction sets.\n",
    "datamodule.prepare_data()  # Create train/val/test/predic dataloaders\n",
    "\n",
    "i, data = next(enumerate(datamodule.val_dataloader()))\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:16.150322407Z",
     "start_time": "2024-01-12T14:54:16.146309722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Check image size\n",
    "print(data[\"image\"].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "`anomalib` supports a wide range of unsupervised anomaly detection models. The table in this [link](https://github.com/openvinotoolkit/anomalib#training) shows the list of models currently supported by `anomalib` library.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Model\n",
    "\n",
    "We will use Padim model for this use case, which could imported from `anomalib.models`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:16.571470266Z",
     "start_time": "2024-01-12T14:54:16.149325935Z"
    }
   },
   "outputs": [],
   "source": [
    "from anomalib.models import Padim\n",
    "\n",
    "model = Padim(\n",
    "    input_size=(256, 256),\n",
    "    backbone=\"resnet18\",\n",
    "    layers=[\"layer1\", \"layer2\", \"layer3\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Callbacks\n",
    "\n",
    "To train the model properly, we will to add some other \"non-essential\" logic such as saving the weights, early-stopping, normalizing the anomaly scores and visualizing the input/output images. To achieve these we use `Callbacks`. Anomalib has its own callbacks and also supports PyTorch Lightning's native callbacks. So, let's create the list of callbacks we want to execute during the training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:16.602378731Z",
     "start_time": "2024-01-12T14:54:16.572501621Z"
    }
   },
   "outputs": [],
   "source": [
    "from anomalib.post_processing import NormalizationMethod, ThresholdMethod\n",
    "from anomalib.utils.callbacks import (\n",
    "    MetricsConfigurationCallback,\n",
    "    MinMaxNormalizationCallback,\n",
    "    PostProcessingConfigurationCallback,\n",
    ")\n",
    "from anomalib.utils.callbacks.export import ExportCallback, ExportMode\n",
    "\n",
    "callbacks = [\n",
    "    MetricsConfigurationCallback(\n",
    "        task=TaskType.CLASSIFICATION,\n",
    "        image_metrics=[\"AUROC\"],\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        mode=\"max\",\n",
    "        monitor=\"image_AUROC\",\n",
    "    ),\n",
    "    PostProcessingConfigurationCallback(\n",
    "        normalization_method=NormalizationMethod.MIN_MAX,\n",
    "        threshold_method=ThresholdMethod.ADAPTIVE,\n",
    "    ),\n",
    "    MinMaxNormalizationCallback(),\n",
    "    ExportCallback(\n",
    "        input_size=(256, 256),\n",
    "        dirpath=str(Path.cwd()),\n",
    "        filename=\"model\",\n",
    "        export_mode=ExportMode.OPENVINO,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now that we set up the datamodule, model and the callbacks, we could now train the model.\n",
    "\n",
    "The final component to train the model is `pytorch_lightning` `Trainer` object, which handles train/test/predict pipeline. Let's create the trainer object to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:23.047614003Z",
     "start_time": "2024-01-12T14:54:16.598832859Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    callbacks=callbacks,\n",
    "    accelerator=\"auto\",\n",
    "    auto_scale_batch_size=False,\n",
    "    check_val_every_n_epoch=1,\n",
    "    devices=1,\n",
    "    gpus=None,\n",
    "    max_epochs=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    val_check_interval=1.0,\n",
    ")\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:23.995467161Z",
     "start_time": "2024-01-12T14:54:23.045618658Z"
    }
   },
   "outputs": [],
   "source": [
    "# Validation\n",
    "test_results = trainer.test(model=model, datamodule=datamodule)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenVINO Inference\n",
    "\n",
    "Now that we trained and tested a model, we could check a single inference result using OpenVINO inferencer object. This will demonstrate how a trained model could be used for inference.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Test Image\n",
    "\n",
    "Let's read an image from the test set and perform inference using OpenVINO inferencer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:24.193546077Z",
     "start_time": "2024-01-12T14:54:23.994606562Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image_path = \"./cubes/abnormal/input_20230210134059.jpg\"\n",
    "image = read_image(path=\"./cubes/abnormal/input_20230210134059.jpg\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the OpenVINO Model\n",
    "\n",
    "By default, the output files are saved into `results` directory. Let's check where the OpenVINO model is stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:24.195000756Z",
     "start_time": "2024-01-12T14:54:24.191985132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "openvino_model_path = Path.cwd() / \"weights\" / \"openvino\" / \"model.bin\"\n",
    "metadata_path = Path.cwd() / \"weights\" / \"openvino\" / \"metadata.json\"\n",
    "print(openvino_model_path.exists(), metadata_path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:45.577666980Z",
     "start_time": "2024-01-12T14:54:45.231788188Z"
    }
   },
   "outputs": [],
   "source": [
    "inferencer = OpenVINOInferencer(\n",
    "    path=openvino_model_path,  # Path to the OpenVINO IR model.\n",
    "    metadata=metadata_path,  # Path to the metadata file.\n",
    "    device=\"CPU\",  # We would like to run it on an Intel CPU.\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Inference\n",
    "\n",
    "Predicting an image using OpenVINO inferencer is as simple as calling `predict` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:48.209353846Z",
     "start_time": "2024-01-12T14:54:48.170721537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)\n",
    "predictions = inferencer.predict(image=image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `predictions` contain any relevant information regarding the task type. For example, predictions for a segmentation model could contain image, anomaly maps, predicted scores, labels or masks.\n",
    "\n",
    "### Visualizing Inference Results\n",
    "\n",
    "`anomalib` provides a number of tools to visualize the inference results. Let's visualize the inference results using the `Visualizer` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:49.998146591Z",
     "start_time": "2024-01-12T14:54:49.919204103Z"
    }
   },
   "outputs": [],
   "source": [
    "from anomalib.post_processing import Visualizer, VisualizationMode\n",
    "from PIL import Image\n",
    "\n",
    "visualizer = Visualizer(mode=VisualizationMode.FULL, task=TaskType.CLASSIFICATION)\n",
    "output_image = visualizer.visualize_image(predictions)\n",
    "Image.fromarray(output_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `predictions` contain a number of information, we could specify which information we want to visualize. For example, if we want to visualize the predicted mask and the segmentation results, we could specify the task type as `TaskType.SEGMENTATION`, which would produce the following visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T14:54:52.948498717Z",
     "start_time": "2024-01-12T14:54:52.861200484Z"
    }
   },
   "outputs": [],
   "source": [
    "visualizer = Visualizer(mode=VisualizationMode.FULL, task=TaskType.SEGMENTATION)\n",
    "output_image = visualizer.visualize_image(predictions)\n",
    "Image.fromarray(output_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomalib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae223df28f60859a2f400fae8b3a1034248e0a469f5599fd9a89c32908ed7a84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
